{"metadata":{"availableInstances":[{"_defaultOrder":0,"_isFastLaunch":true,"category":"General purpose","gpuNum":0,"memoryGiB":4,"name":"ml.t3.medium","vcpuNum":2},{"_defaultOrder":1,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":8,"name":"ml.t3.large","vcpuNum":2},{"_defaultOrder":2,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":16,"name":"ml.t3.xlarge","vcpuNum":4},{"_defaultOrder":3,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":32,"name":"ml.t3.2xlarge","vcpuNum":8},{"_defaultOrder":4,"_isFastLaunch":true,"category":"General purpose","gpuNum":0,"memoryGiB":8,"name":"ml.m5.large","vcpuNum":2},{"_defaultOrder":5,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":16,"name":"ml.m5.xlarge","vcpuNum":4},{"_defaultOrder":6,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":32,"name":"ml.m5.2xlarge","vcpuNum":8},{"_defaultOrder":7,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":64,"name":"ml.m5.4xlarge","vcpuNum":16},{"_defaultOrder":8,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":128,"name":"ml.m5.8xlarge","vcpuNum":32},{"_defaultOrder":9,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":192,"name":"ml.m5.12xlarge","vcpuNum":48},{"_defaultOrder":10,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":256,"name":"ml.m5.16xlarge","vcpuNum":64},{"_defaultOrder":11,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":384,"name":"ml.m5.24xlarge","vcpuNum":96},{"_defaultOrder":12,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":8,"name":"ml.m5d.large","vcpuNum":2},{"_defaultOrder":13,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":16,"name":"ml.m5d.xlarge","vcpuNum":4},{"_defaultOrder":14,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":32,"name":"ml.m5d.2xlarge","vcpuNum":8},{"_defaultOrder":15,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":64,"name":"ml.m5d.4xlarge","vcpuNum":16},{"_defaultOrder":16,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":128,"name":"ml.m5d.8xlarge","vcpuNum":32},{"_defaultOrder":17,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":192,"name":"ml.m5d.12xlarge","vcpuNum":48},{"_defaultOrder":18,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":256,"name":"ml.m5d.16xlarge","vcpuNum":64},{"_defaultOrder":19,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"memoryGiB":384,"name":"ml.m5d.24xlarge","vcpuNum":96},{"_defaultOrder":20,"_isFastLaunch":true,"category":"Compute optimized","gpuNum":0,"memoryGiB":4,"name":"ml.c5.large","vcpuNum":2},{"_defaultOrder":21,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"memoryGiB":8,"name":"ml.c5.xlarge","vcpuNum":4},{"_defaultOrder":22,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"memoryGiB":16,"name":"ml.c5.2xlarge","vcpuNum":8},{"_defaultOrder":23,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"memoryGiB":32,"name":"ml.c5.4xlarge","vcpuNum":16},{"_defaultOrder":24,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"memoryGiB":72,"name":"ml.c5.9xlarge","vcpuNum":36},{"_defaultOrder":25,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"memoryGiB":96,"name":"ml.c5.12xlarge","vcpuNum":48},{"_defaultOrder":26,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"memoryGiB":144,"name":"ml.c5.18xlarge","vcpuNum":72},{"_defaultOrder":27,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"memoryGiB":192,"name":"ml.c5.24xlarge","vcpuNum":96},{"_defaultOrder":28,"_isFastLaunch":true,"category":"Accelerated computing","gpuNum":1,"memoryGiB":16,"name":"ml.g4dn.xlarge","vcpuNum":4},{"_defaultOrder":29,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"memoryGiB":32,"name":"ml.g4dn.2xlarge","vcpuNum":8},{"_defaultOrder":30,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"memoryGiB":64,"name":"ml.g4dn.4xlarge","vcpuNum":16},{"_defaultOrder":31,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"memoryGiB":128,"name":"ml.g4dn.8xlarge","vcpuNum":32},{"_defaultOrder":32,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"memoryGiB":192,"name":"ml.g4dn.12xlarge","vcpuNum":48},{"_defaultOrder":33,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"memoryGiB":256,"name":"ml.g4dn.16xlarge","vcpuNum":64},{"_defaultOrder":34,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"memoryGiB":61,"name":"ml.p3.2xlarge","vcpuNum":8},{"_defaultOrder":35,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"memoryGiB":244,"name":"ml.p3.8xlarge","vcpuNum":32},{"_defaultOrder":36,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"memoryGiB":488,"name":"ml.p3.16xlarge","vcpuNum":64},{"_defaultOrder":37,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"memoryGiB":768,"name":"ml.p3dn.24xlarge","vcpuNum":96},{"_defaultOrder":38,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"memoryGiB":16,"name":"ml.r5.large","vcpuNum":2},{"_defaultOrder":39,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"memoryGiB":32,"name":"ml.r5.xlarge","vcpuNum":4},{"_defaultOrder":40,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"memoryGiB":64,"name":"ml.r5.2xlarge","vcpuNum":8},{"_defaultOrder":41,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"memoryGiB":128,"name":"ml.r5.4xlarge","vcpuNum":16},{"_defaultOrder":42,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"memoryGiB":256,"name":"ml.r5.8xlarge","vcpuNum":32},{"_defaultOrder":43,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"memoryGiB":384,"name":"ml.r5.12xlarge","vcpuNum":48},{"_defaultOrder":44,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"memoryGiB":512,"name":"ml.r5.16xlarge","vcpuNum":64},{"_defaultOrder":45,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"memoryGiB":768,"name":"ml.r5.24xlarge","vcpuNum":96},{"_defaultOrder":46,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"memoryGiB":16,"name":"ml.g5.xlarge","vcpuNum":4},{"_defaultOrder":47,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"memoryGiB":32,"name":"ml.g5.2xlarge","vcpuNum":8},{"_defaultOrder":48,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"memoryGiB":64,"name":"ml.g5.4xlarge","vcpuNum":16},{"_defaultOrder":49,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"memoryGiB":128,"name":"ml.g5.8xlarge","vcpuNum":32},{"_defaultOrder":50,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"memoryGiB":256,"name":"ml.g5.16xlarge","vcpuNum":64},{"_defaultOrder":51,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"memoryGiB":192,"name":"ml.g5.12xlarge","vcpuNum":48},{"_defaultOrder":52,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"memoryGiB":384,"name":"ml.g5.24xlarge","vcpuNum":96},{"_defaultOrder":53,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"memoryGiB":768,"name":"ml.g5.48xlarge","vcpuNum":192}],"instance_type":"ml.t3.medium","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Mobile Price Classification using SKLearn Custom Script in Sagemaker","metadata":{"tags":[]}},{"cell_type":"code","source":"import sagemaker\nfrom sklearn.model_selection import train_test_split\nimport boto3\nimport pandas as pd\n\nsm_boto3 = boto3.client(\"sagemaker\")\nsess = sagemaker.Session()\nregion = sess.boto_session.region_name\nbucket = 'mobbucketsagemaker' # Mention the created S3 bucket name here\nprint(\"Using bucket \" + bucket)","metadata":{"tags":[]},"execution_count":1,"outputs":[{"name":"stdout","output_type":"stream","text":"Using bucket mobbucketsagemaker\n"}]},{"cell_type":"markdown","source":"The code seems to set up a SageMaker session and defines some variables for later use. Let's break it down into bullet points:\n\n* The code imports the necessary libraries: sagemaker, train_test_split from sklearn.model_selection, boto3, and pandas.\n* It creates a Boto3 client for SageMaker using boto3.client(\"sagemaker\").\n* It initiates a SageMaker session using sagemaker.Session().\n* The region name of the current session is stored in the region variable.\n* It sets the S3 bucket name to 'mobbucketsagemaker' and stores it in the bucket variable.\n* Finally, it prints the message \"Using bucket \" followed by the S3 bucket name to indicate which bucket will be used.\n* It's important to note that this code snippet by itself does not perform any specific machine learning tasks or operations; rather, it sets up the necessary environment to work with SageMaker and specifies the S3 bucket to use for storing data and model artifacts. Additional code will be required to perform actual machine learning tasks using SageMaker.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"mob_price_classification_train.csv\")","metadata":{"tags":[]},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"- It reads the data from the CSV file \"mob_price_classification_train.csv\" and creates a pandas DataFrame called 'df' to store the data.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"tags":[]},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>battery_power</th>\n","      <th>blue</th>\n","      <th>clock_speed</th>\n","      <th>dual_sim</th>\n","      <th>fc</th>\n","      <th>four_g</th>\n","      <th>int_memory</th>\n","      <th>m_dep</th>\n","      <th>mobile_wt</th>\n","      <th>n_cores</th>\n","      <th>...</th>\n","      <th>px_height</th>\n","      <th>px_width</th>\n","      <th>ram</th>\n","      <th>sc_h</th>\n","      <th>sc_w</th>\n","      <th>talk_time</th>\n","      <th>three_g</th>\n","      <th>touch_screen</th>\n","      <th>wifi</th>\n","      <th>price_range</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842</td>\n","      <td>0</td>\n","      <td>2.2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0.6</td>\n","      <td>188</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>20</td>\n","      <td>756</td>\n","      <td>2549</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1021</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>53</td>\n","      <td>0.7</td>\n","      <td>136</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>905</td>\n","      <td>1988</td>\n","      <td>2631</td>\n","      <td>17</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>563</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>41</td>\n","      <td>0.9</td>\n","      <td>145</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>1263</td>\n","      <td>1716</td>\n","      <td>2603</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>615</td>\n","      <td>1</td>\n","      <td>2.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0.8</td>\n","      <td>131</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>1216</td>\n","      <td>1786</td>\n","      <td>2769</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1821</td>\n","      <td>1</td>\n","      <td>1.2</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>44</td>\n","      <td>0.6</td>\n","      <td>141</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1208</td>\n","      <td>1212</td>\n","      <td>1411</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n","0            842     0          2.2         0   1       0           7    0.6   \n","1           1021     1          0.5         1   0       1          53    0.7   \n","2            563     1          0.5         1   2       1          41    0.9   \n","3            615     1          2.5         0   0       0          10    0.8   \n","4           1821     1          1.2         0  13       1          44    0.6   \n","\n","   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n","0        188        2  ...         20       756  2549     9     7         19   \n","1        136        3  ...        905      1988  2631    17     3          7   \n","2        145        5  ...       1263      1716  2603    11     2          9   \n","3        131        6  ...       1216      1786  2769    16     8         11   \n","4        141        2  ...       1208      1212  1411     8     2         15   \n","\n","   three_g  touch_screen  wifi  price_range  \n","0        0             0     1            1  \n","1        1             1     0            2  \n","2        1             1     0            2  \n","3        1             0     0            2  \n","4        1             1     0            1  \n","\n","[5 rows x 21 columns]"]},"metadata":{}}]},{"cell_type":"markdown","source":"- The df.head() function is used to display the first few rows of the pandas DataFrame 'df'. This function is commonly used to quickly inspect the data and get an overview of its structure. It is especially useful for understanding the column names and the data types present in the DataFrame.","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"tags":[]},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":["(2000, 21)"]},"metadata":{}}]},{"cell_type":"markdown","source":"The df.shape attribute is used to determine the dimensions (number of rows and columns) of the pandas DataFrame 'df'. It returns a tuple with two elements:\n\n* The first element represents the number of rows in the DataFrame.\n* The second element represents the number of columns in the DataFrame.","metadata":{}},{"cell_type":"code","source":"# ['Low_Risk','High_Risk'],[0,1]\ndf['price_range'].value_counts(normalize=True)","metadata":{"tags":[]},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":["price_range\n","1    0.25\n","2    0.25\n","3    0.25\n","0    0.25\n","Name: proportion, dtype: float64"]},"metadata":{}}]},{"cell_type":"markdown","source":"The code you provided is likely used to analyze the distribution of values in the 'price_range' column of the pandas DataFrame 'df'. The 'price_range' column seems to contain categorical data representing different price ranges for mobile devices.\n\nHere's what the code does:\n\n* df['price_range'] refers to the 'price_range' column in the DataFrame 'df'.\n* value_counts() is a pandas function that counts the occurrences of each unique value in the specified column. It returns a Series where the index is the unique value and the value is the count of occurrences.\n* normalize=True is used as an argument to the value_counts() function to get the relative frequencies (proportions) of each unique value instead of the raw counts.","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"tags":[]},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":["Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n","       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n","       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n","       'touch_screen', 'wifi', 'price_range'],\n","      dtype='object')"]},"metadata":{}}]},{"cell_type":"markdown","source":"The df.columns attribute is used to get a list of column names present in the pandas DataFrame 'df'. It provides an easy way to access and inspect the names of the columns in the DataFrame.\n\nWhen you execute df.columns, it will return an array-like object (usually a pandas Index or a list) containing the column names of the DataFrame.","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"tags":[]},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":["(2000, 21)"]},"metadata":{}}]},{"cell_type":"code","source":"# Find the Percentage of Values are missing\ndf.isnull().mean() * 100","metadata":{"tags":[]},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":["battery_power    0.0\n","blue             0.0\n","clock_speed      0.0\n","dual_sim         0.0\n","fc               0.0\n","four_g           0.0\n","int_memory       0.0\n","m_dep            0.0\n","mobile_wt        0.0\n","n_cores          0.0\n","pc               0.0\n","px_height        0.0\n","px_width         0.0\n","ram              0.0\n","sc_h             0.0\n","sc_w             0.0\n","talk_time        0.0\n","three_g          0.0\n","touch_screen     0.0\n","wifi             0.0\n","price_range      0.0\n","dtype: float64"]},"metadata":{}}]},{"cell_type":"markdown","source":"The code provided calculates the percentage of missing values in each column of the pandas DataFrame 'df'. Here's what the code does:\n\n* df.isnull() returns a DataFrame of the same shape as 'df' where each cell contains a boolean value indicating whether the corresponding cell in 'df' is null (True) or not null (False).\n* .mean() is then used to calculate the mean (average) of each column. Since the boolean values are treated as 1 for True and 0 for False, taking the mean effectively calculates the proportion of True (missing) values in each column.\n* Finally, * 100 is used to convert the proportions to percentages, giving the percentage of missing values in each column.","metadata":{}},{"cell_type":"code","source":"features = list(df.columns)\nfeatures","metadata":{"tags":[]},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":["['battery_power',\n"," 'blue',\n"," 'clock_speed',\n"," 'dual_sim',\n"," 'fc',\n"," 'four_g',\n"," 'int_memory',\n"," 'm_dep',\n"," 'mobile_wt',\n"," 'n_cores',\n"," 'pc',\n"," 'px_height',\n"," 'px_width',\n"," 'ram',\n"," 'sc_h',\n"," 'sc_w',\n"," 'talk_time',\n"," 'three_g',\n"," 'touch_screen',\n"," 'wifi',\n"," 'price_range']"]},"metadata":{}}]},{"cell_type":"markdown","source":"The code creates a list named features containing the column names of the pandas DataFrame 'df'. Here's what the code does:\n\n* df.columns returns an array-like object (usually a pandas Index or a list) containing the column names of the DataFrame 'df'.\n* list(df.columns) converts the array-like object to a regular Python list.","metadata":{}},{"cell_type":"code","source":"label = features.pop(-1)\nlabel","metadata":{"tags":[]},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":["'price_range'"]},"metadata":{}}]},{"cell_type":"markdown","source":"The code pops the last element from the features list and assigns it to the variable label. The pop() method in Python removes and returns the element at the specified index (in this case, -1 refers to the last element in the list).\n\nHere's what the code does:\n\n* features.pop(-1) removes the last element from the features list and returns its value.\n* The value returned by features.pop(-1) is assigned to the variable label.","metadata":{}},{"cell_type":"code","source":"x = df[features]\ny = df[label]","metadata":{"tags":[]},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"In code, the DataFrame 'df' is being split into two separate datasets: 'x' and 'y'. This is commonly done when preparing data for machine learning tasks, where 'x' typically represents the features or input data, and 'y' represents the target or output labels that we want the model to learn and predict.\n\nHere's what the code does:\n\n* df[features]: This line creates a new DataFrame 'x' by selecting only the columns specified in the features list. 'x' will contain the data corresponding to the columns listed in 'features'. It represents the input features for the machine learning model.\n* df[label]: This line creates a new Series 'y' by selecting the column specified by the variable label. 'y' will contain the data corresponding to the column represented by label. It represents the target variable or the output labels for the machine learning model.","metadata":{}},{"cell_type":"code","source":"x.head()","metadata":{"tags":[]},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>battery_power</th>\n","      <th>blue</th>\n","      <th>clock_speed</th>\n","      <th>dual_sim</th>\n","      <th>fc</th>\n","      <th>four_g</th>\n","      <th>int_memory</th>\n","      <th>m_dep</th>\n","      <th>mobile_wt</th>\n","      <th>n_cores</th>\n","      <th>pc</th>\n","      <th>px_height</th>\n","      <th>px_width</th>\n","      <th>ram</th>\n","      <th>sc_h</th>\n","      <th>sc_w</th>\n","      <th>talk_time</th>\n","      <th>three_g</th>\n","      <th>touch_screen</th>\n","      <th>wifi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842</td>\n","      <td>0</td>\n","      <td>2.2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0.6</td>\n","      <td>188</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>756</td>\n","      <td>2549</td>\n","      <td>9</td>\n","      <td>7</td>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1021</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>53</td>\n","      <td>0.7</td>\n","      <td>136</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>905</td>\n","      <td>1988</td>\n","      <td>2631</td>\n","      <td>17</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>563</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>41</td>\n","      <td>0.9</td>\n","      <td>145</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>1263</td>\n","      <td>1716</td>\n","      <td>2603</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>615</td>\n","      <td>1</td>\n","      <td>2.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0.8</td>\n","      <td>131</td>\n","      <td>6</td>\n","      <td>9</td>\n","      <td>1216</td>\n","      <td>1786</td>\n","      <td>2769</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1821</td>\n","      <td>1</td>\n","      <td>1.2</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>44</td>\n","      <td>0.6</td>\n","      <td>141</td>\n","      <td>2</td>\n","      <td>14</td>\n","      <td>1208</td>\n","      <td>1212</td>\n","      <td>1411</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n","0            842     0          2.2         0   1       0           7    0.6   \n","1           1021     1          0.5         1   0       1          53    0.7   \n","2            563     1          0.5         1   2       1          41    0.9   \n","3            615     1          2.5         0   0       0          10    0.8   \n","4           1821     1          1.2         0  13       1          44    0.6   \n","\n","   mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n","0        188        2   2         20       756  2549     9     7         19   \n","1        136        3   6        905      1988  2631    17     3          7   \n","2        145        5   6       1263      1716  2603    11     2          9   \n","3        131        6   9       1216      1786  2769    16     8         11   \n","4        141        2  14       1208      1212  1411     8     2         15   \n","\n","   three_g  touch_screen  wifi  \n","0        0             0     1  \n","1        1             1     0  \n","2        1             1     0  \n","3        1             0     0  \n","4        1             1     0  "]},"metadata":{}}]},{"cell_type":"markdown","source":"The x.head() function is used to quickly inspect the first few rows of the DataFrame 'x' and get an overview of its structure and data. The actual output will vary based on the data present in your 'x' DataFrame.","metadata":{}},{"cell_type":"code","source":"# {0: 'Low_Risk',1: 'High_Risk'}\ny.head()","metadata":{"tags":[]},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":["0    1\n","1    2\n","2    2\n","3    2\n","4    1\n","Name: price_range, dtype: int64"]},"metadata":{}}]},{"cell_type":"markdown","source":"The y.head() function displays the first few rows of the 'y' Series, which by default is the first 5 rows. Each row represents the target label for the corresponding row in the 'x' DataFrame.","metadata":{}},{"cell_type":"code","source":"x.shape","metadata":{"tags":[]},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":["(2000, 20)"]},"metadata":{}}]},{"cell_type":"code","source":"y.value_counts()","metadata":{"tags":[]},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":["price_range\n","1    500\n","2    500\n","3    500\n","0    500\n","Name: count, dtype: int64"]},"metadata":{}}]},{"cell_type":"markdown","source":"The y.value_counts() function is used to count the occurrences of each unique value in the Series 'y'. In this case, 'y' represents the target variable or output labels, and we want to understand the distribution of different label values in the Series.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.15, random_state=0)","metadata":{"tags":[]},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"The code provided performs a train-test split on the input features ('x') and the target variable ('y') using the train_test_split function from scikit-learn. This is a common technique used in machine learning to divide the data into two sets: one for training the model and another for testing its performance.\n\nHere's what the code does:\n\n* train_test_split(x, y, test_size=0.15, random_state=0): This function takes the input features 'x' and the target variable 'y' as inputs and splits them into four sets: 'X_train', 'X_test', 'y_train', and 'y_test'.\n* test_size=0.15: This parameter specifies the proportion of the data that should be allocated to the test set. In this case, 15% of the data will be used for testing, and the remaining 85% will be used for training.\n* random_state=0: This parameter is used to set the random seed for reproducibility. By setting it to a specific value (e.g., 0), the train-test split will always produce the same result when executed multiple times.\n\nAfter executing the code, you will have the following sets:\n\n* 'X_train': The training set of input features.\n* 'X_test': The test set of input features.\n* 'y_train': The training set of target variable (labels).\n* 'y_test': The test set of target variable (labels).\n\nThese sets can be used to train a machine learning model on the training data and evaluate its performance on the test data.","metadata":{}},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"tags":[]},"execution_count":17,"outputs":[{"name":"stdout","output_type":"stream","text":"(1700, 20)\n\n(300, 20)\n\n(1700,)\n\n(300,)\n"}]},{"cell_type":"markdown","source":"These shapes indicate the number of samples (rows) and features (columns) in the input feature DataFrames and the number of samples in the target label Series.","metadata":{}},{"cell_type":"code","source":"trainX = pd.DataFrame(X_train)\ntrainX[label] = y_train\n\ntestX = pd.DataFrame(X_test)\ntestX[label] = y_test","metadata":{"tags":[]},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"In the code, new DataFrames named 'trainX' and 'testX' are created to combine the training and test sets of input features 'X_train' and 'X_test', respectively, with their corresponding target labels 'y_train' and 'y_test'.\n\nHere's what the code does:\n\n- trainX = pd.DataFrame(X_train): This line creates a new DataFrame 'trainX' from the training set of input features 'X_train'. The columns in 'trainX' will be the same as in 'X_train'.\n- trainX[label] = y_train: This line adds a new column to 'trainX' with the name specified by the variable 'label', and populates it with the values from the training set of target labels 'y_train'. This step effectively adds the target variable as a new column in the training set.\n- testX = pd.DataFrame(X_test): This line creates a new DataFrame 'testX' from the test set of input features 'X_test'. The columns in 'testX' will be the same as in 'X_test'.\n- testX[label] = y_test: This line adds a new column to 'testX' with the name specified by the variable 'label', and populates it with the values from the test set of target labels 'y_test'. This step effectively adds the target variable as a new column in the test set.\n\nThe resulting 'trainX' and 'testX' DataFrames will have the target variable as one of their columns, allowing you to use them for training and testing machine learning models that require the input features and their corresponding target labels in a single DataFrame.","metadata":{}},{"cell_type":"code","source":"print(trainX.shape)\nprint(testX.shape)","metadata":{"tags":[]},"execution_count":19,"outputs":[{"name":"stdout","output_type":"stream","text":"(1700, 21)\n\n(300, 21)\n"}]},{"cell_type":"code","source":"trainX.head()","metadata":{"tags":[]},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>battery_power</th>\n","      <th>blue</th>\n","      <th>clock_speed</th>\n","      <th>dual_sim</th>\n","      <th>fc</th>\n","      <th>four_g</th>\n","      <th>int_memory</th>\n","      <th>m_dep</th>\n","      <th>mobile_wt</th>\n","      <th>n_cores</th>\n","      <th>...</th>\n","      <th>px_height</th>\n","      <th>px_width</th>\n","      <th>ram</th>\n","      <th>sc_h</th>\n","      <th>sc_w</th>\n","      <th>talk_time</th>\n","      <th>three_g</th>\n","      <th>touch_screen</th>\n","      <th>wifi</th>\n","      <th>price_range</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1452</th>\n","      <td>1450</td>\n","      <td>0</td>\n","      <td>2.1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>31</td>\n","      <td>0.6</td>\n","      <td>114</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>1573</td>\n","      <td>1639</td>\n","      <td>794</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1044</th>\n","      <td>1218</td>\n","      <td>1</td>\n","      <td>2.8</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>39</td>\n","      <td>0.8</td>\n","      <td>150</td>\n","      <td>7</td>\n","      <td>...</td>\n","      <td>1122</td>\n","      <td>1746</td>\n","      <td>1667</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1279</th>\n","      <td>1602</td>\n","      <td>0</td>\n","      <td>0.6</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>58</td>\n","      <td>0.4</td>\n","      <td>170</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1259</td>\n","      <td>1746</td>\n","      <td>3622</td>\n","      <td>17</td>\n","      <td>2</td>\n","      <td>17</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>674</th>\n","      <td>1034</td>\n","      <td>0</td>\n","      <td>2.6</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>45</td>\n","      <td>0.3</td>\n","      <td>190</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>182</td>\n","      <td>1293</td>\n","      <td>969</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1200</th>\n","      <td>530</td>\n","      <td>0</td>\n","      <td>2.4</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>32</td>\n","      <td>0.3</td>\n","      <td>88</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>48</td>\n","      <td>1012</td>\n","      <td>959</td>\n","      <td>17</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n","1452           1450     0          2.1         0   1       0          31   \n","1044           1218     1          2.8         1   3       0          39   \n","1279           1602     0          0.6         0  12       0          58   \n","674            1034     0          2.6         1   2       1          45   \n","1200            530     0          2.4         0   1       0          32   \n","\n","      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n","1452    0.6        114        5  ...       1573      1639   794    11     5   \n","1044    0.8        150        7  ...       1122      1746  1667    10     0   \n","1279    0.4        170        1  ...       1259      1746  3622    17     2   \n","674     0.3        190        3  ...        182      1293   969    15     1   \n","1200    0.3         88        6  ...         48      1012   959    17     7   \n","\n","      talk_time  three_g  touch_screen  wifi  price_range  \n","1452          9        0             1     1            1  \n","1044         12        0             0     0            1  \n","1279         17        0             1     1            3  \n","674           7        1             0     0            0  \n","1200          6        0             1     0            0  \n","\n","[5 rows x 21 columns]"]},"metadata":{}}]},{"cell_type":"code","source":"trainX.isnull().sum()","metadata":{"tags":[]},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":["battery_power    0\n","blue             0\n","clock_speed      0\n","dual_sim         0\n","fc               0\n","four_g           0\n","int_memory       0\n","m_dep            0\n","mobile_wt        0\n","n_cores          0\n","pc               0\n","px_height        0\n","px_width         0\n","ram              0\n","sc_h             0\n","sc_w             0\n","talk_time        0\n","three_g          0\n","touch_screen     0\n","wifi             0\n","price_range      0\n","dtype: int64"]},"metadata":{}}]},{"cell_type":"markdown","source":"The code snippet seems to be written in Python and is likely related to data analysis using pandas. The code is checking for null values in a pandas DataFrame called trainX and then calculating the sum of null values for each column.\n\nHere's a breakdown of what the code does:\n\n- trainX: It is assumed to be a pandas DataFrame containing the training data.\n- isnull(): This is a pandas DataFrame method that checks for missing or null values in the DataFrame and returns a DataFrame of the same shape with boolean values, where True indicates a missing value and False indicates a non-null value.\n- sum(): After calling isnull(), the sum() method is used on the resulting DataFrame to calculate the sum of True values (i.e., the number of missing values) for each column","metadata":{}},{"cell_type":"code","source":"testX.isnull().sum()","metadata":{"tags":[]},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":["battery_power    0\n","blue             0\n","clock_speed      0\n","dual_sim         0\n","fc               0\n","four_g           0\n","int_memory       0\n","m_dep            0\n","mobile_wt        0\n","n_cores          0\n","pc               0\n","px_height        0\n","px_width         0\n","ram              0\n","sc_h             0\n","sc_w             0\n","talk_time        0\n","three_g          0\n","touch_screen     0\n","wifi             0\n","price_range      0\n","dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"trainX.to_csv(\"train-V-1.csv\",index = False)\ntestX.to_csv(\"test-V-1.csv\", index = False)","metadata":{"tags":[]},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"In the code, the DataFrames 'trainX' and 'testX' are saved as CSV files named \"train-V-1.csv\" and \"test-V-1.csv\", respectively. The to_csv() method is used to export the DataFrames to CSV format.\n\nHere's what the code does:\n\n- trainX.to_csv(\"train-V-1.csv\", index=False): This line saves the DataFrame 'trainX' to a CSV file named \"train-V-1.csv\" in the current working directory. The index=False parameter ensures that the DataFrame's index is not included in the CSV file.\n- testX.to_csv(\"test-V-1.csv\", index=False): This line saves the DataFrame 'testX' to a CSV file named \"test-V-1.csv\" in the current working directory. The index=False parameter ensures that the DataFrame's index is not included in the CSV file.\n\nAfter executing this code, you will find two CSV files named \"train-V-1.csv\" and \"test-V-1.csv\" in the same location where your Python script is located (assuming no specific path is given). These files will contain the data from 'trainX' and 'testX', respectively, in CSV format, and can be used for further analysis, model training, or sharing the data with others","metadata":{}},{"cell_type":"code","source":"bucket","metadata":{},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":["'mobbucketsagemaker'"]},"metadata":{}}]},{"cell_type":"markdown","source":"In the provided code, the variable bucket is assigned a value of \"mobbucketsagemaker.\" The value \"mobbucketsagemaker\" is likely used to represent the name of an Amazon S3 bucket.\n\nAmazon S3 (Simple Storage Service) is a cloud-based storage service provided by Amazon Web Services (AWS). Buckets are containers for storing objects (files) in S3. Each object in S3 is identified by a unique key, which is the combination of the object's name and the bucket name.\n\nUsing S3 buckets, you can store various types of data, such as files, images, videos, or any other type of data you need to store securely in the cloud. S3 buckets are widely used for various purposes, including data storage for applications, data backups, data sharing, and serving static content for websites.\n\nThe code snippet you provided doesn't perform any specific actions with the 'bucket' variable. It is merely setting the name of the S3 bucket in the variable, which may be used in later parts of the code for interacting with the specified bucket on AWS.","metadata":{}},{"cell_type":"code","source":"# send data to S3. SageMaker will take training data from s3\nsk_prefix = \"sagemaker/mobile_price_classification/sklearncontainer\"\ntrainpath = sess.upload_data(\n    path=\"train-V-1.csv\", bucket=bucket, key_prefix=sk_prefix\n)\n\ntestpath = sess.upload_data(\n    path=\"test-V-1.csv\", bucket=bucket, key_prefix=sk_prefix\n)\nprint(trainpath)\nprint(testpath)","metadata":{"tags":[]},"execution_count":25,"outputs":[{"name":"stdout","output_type":"stream","text":"s3://mobbucketsagemaker/sagemaker/mobile_price_classification/sklearncontainer/train-V-1.csv\n\ns3://mobbucketsagemaker/sagemaker/mobile_price_classification/sklearncontainer/test-V-1.csv\n"}]},{"cell_type":"markdown","source":"In the provided code, the SageMaker sess.upload_data() function is used to upload the data from local files \"train-V-1.csv\" and \"test-V-1.csv\" to the specified Amazon S3 bucket. This is a common process when preparing data for SageMaker training jobs, where the data needs to be available in an S3 bucket for the training to take place.\n\nHere's what the code does:\n\n1. sk_prefix = \"sagemaker/mobile_price_classification/sklearncontainer\": This line sets the prefix for the S3 key (object name) under which the data will be stored. It's a way of organizing the data within the specified S3 bucket.\n2. trainpath = sess.upload_data(path=\"train-V-1.csv\", bucket=bucket, key_prefix=sk_prefix): This line uploads the local file \"train-V-1.csv\" to the specified S3 bucket. The sess.upload_data() function takes the path of the local file to upload, the target S3 bucket specified by the variable bucket, and the key prefix to organize the data within the bucket. The function returns the S3 path where the file was uploaded.\n3. testpath = sess.upload_data(path=\"test-V-1.csv\", bucket=bucket, key_prefix=sk_prefix): This line uploads the local file \"test-V-1.csv\" to the same S3 bucket using the same key prefix. The sess.upload_data() function is used again to upload the file, and it returns the S3 path.\n4. print(trainpath): This line prints the S3 path where the \"train-V-1.csv\" file was uploaded.\n5. print(testpath): This line prints the S3 path where the \"test-V-1.csv\" file was uploaded.\n\nThe output of the print(trainpath) and print(testpath) statements will be the URLs of the uploaded files in the S3 bucket. These URLs will be used later to reference the data when setting up and running the SageMaker training job using the specified data.","metadata":{}},{"cell_type":"code","source":"%%writefile script.py\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc\nimport sklearn\nimport joblib\nimport boto3\nimport pathlib\nfrom io import StringIO \nimport argparse\nimport joblib\nimport os\nimport numpy as np\nimport pandas as pd\n    \ndef model_fn(model_dir):\n    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n    return clf\n    \nif __name__ == \"__main__\":\n\n    print(\"[INFO] Extracting arguments\")\n    parser = argparse.ArgumentParser()\n\n    # hyperparameters sent by the client are passed as command-line arguments to the script.\n    parser.add_argument(\"--n_estimators\", type=int, default=100)\n    parser.add_argument(\"--random_state\", type=int, default=0)\n\n    # Data, model, and output directories\n    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n    parser.add_argument(\"--train-file\", type=str, default=\"train-V-1.csv\")\n    parser.add_argument(\"--test-file\", type=str, default=\"test-V-1.csv\")\n\n    args, _ = parser.parse_known_args()\n    \n    print(\"SKLearn Version: \", sklearn.__version__)\n    print(\"Joblib Version: \", joblib.__version__)\n\n    print(\"[INFO] Reading data\")\n    print()\n    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n    \n    features = list(train_df.columns)\n    label = features.pop(-1)\n    \n    print(\"Building training and testing datasets\")\n    print()\n    X_train = train_df[features]\n    X_test = test_df[features]\n    y_train = train_df[label]\n    y_test = test_df[label]\n\n    print('Column order: ')\n    print(features)\n    print()\n    \n    print(\"Label column is: \",label)\n    print()\n    \n    print(\"Data Shape: \")\n    print()\n    print(\"---- SHAPE OF TRAINING DATA (85%) ----\")\n    print(X_train.shape)\n    print(y_train.shape)\n    print()\n    print(\"---- SHAPE OF TESTING DATA (15%) ----\")\n    print(X_test.shape)\n    print(y_test.shape)\n    print()\n    \n  \n    print(\"Training RandomForest Model.....\")\n    print()\n    model =  RandomForestClassifier(n_estimators=args.n_estimators, random_state=args.random_state, verbose = 3,n_jobs=-1)\n    model.fit(X_train, y_train)\n    print()\n    \n\n    model_path = os.path.join(args.model_dir, \"model.joblib\")\n    joblib.dump(model,model_path)\n    print(\"Model persisted at \" + model_path)\n    print()\n\n    \n    y_pred_test = model.predict(X_test)\n    test_acc = accuracy_score(y_test,y_pred_test)\n    test_rep = classification_report(y_test,y_pred_test)\n\n    print()\n    print(\"---- METRICS RESULTS FOR TESTING DATA ----\")\n    print()\n    print(\"Total Rows are: \", X_test.shape[0])\n    print('[TESTING] Model Accuracy is: ', test_acc)\n    print('[TESTING] Testing Report: ')\n    print(test_rep)","metadata":{"tags":[]},"execution_count":26,"outputs":[{"name":"stdout","output_type":"stream","text":"Writing script.py\n"}]},{"cell_type":"markdown","source":"The provided Python script appears to be an implementation of a machine learning model using Scikit-learn's RandomForestClassifier. It performs training and testing of the model and saves the trained model using joblib. The script also prints various metrics results for the testing data. The script is designed to be run as part of an Amazon SageMaker training job.\n\nHere's an overview of the key sections of the script:\n\n1. model_fn: A function that loads the trained model from the specified model directory. This function will be used by SageMaker to load the model during deployment.\n2. Main Script:\n\n- The script starts by extracting the hyperparameters and data directories from the command-line arguments passed by SageMaker.\n- It reads the training and testing data from the respective CSV files specified by the arguments.\n- It builds the training and testing datasets by separating the input features and target labels.\n- The RandomForestClassifier model is trained on the training dataset (X_train and y_train).\n- The trained model is saved using joblib, and the file is stored in the specified model directory.\n- The model's performance is evaluated on the testing dataset (X_test and y_test) using accuracy and classification report.\n- The final model is persisted to the model directory, and metrics results are printed.\n\nThis script follows the structure required for running a Scikit-learn model as a SageMaker training job. The input data is passed through the SM_CHANNEL_TRAIN and SM_CHANNEL_TEST environment variables, and the trained model is saved in the SM_MODEL_DIR directory. The script also extracts hyperparameters using command-line arguments, allowing easy configuration of the model during SageMaker training.","metadata":{}},{"cell_type":"code","source":"from sagemaker.sklearn.estimator import SKLearn\n\nFRAMEWORK_VERSION = \"0.23-1\"\n\nsklearn_estimator = SKLearn(\n    entry_point=\"script.py\",\n    role=\"arn:aws:iam::566373416292:role/service-role/AmazonSageMaker-ExecutionRole-20230120T164209\",\n    instance_count=1,\n    instance_type=\"ml.m5.large\",\n    framework_version=FRAMEWORK_VERSION,\n    base_job_name=\"RF-custom-sklearn\",\n    hyperparameters={\n        \"n_estimators\": 100,\n        \"random_state\": 0,\n    },\n    use_spot_instances = True,\n    max_wait = 7200,\n    max_run = 3600\n)","metadata":{"tags":[]},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"The provided code sets up an Amazon SageMaker SKLearn Estimator for training a custom Scikit-learn model on AWS SageMaker. The estimator defines the configuration required for the training job, including the script to be executed, the instance type for training, hyperparameters, and other settings.\n\nHere's a breakdown of the key settings and options:\n\n- entry_point: The name of the script file that contains the custom Scikit-learn model implementation. In this case, it is \"script.py.\"\n- role: The Amazon Resource Name (ARN) of the IAM role that SageMaker will assume to perform tasks on your behalf. This role should have the necessary permissions for reading data from S3 and writing model artifacts to S3.\n- instance_count: The number of instances to use for training. In this case, a single instance (1) will be used.\n- instance_type: The type of EC2 instance to use for training. Here, it is set to \"ml.m5.large.\"\n- framework_version: The version of Scikit-learn to be used during training. The provided version is \"0.23-1.\"\n- base_job_name: A unique name that will be used as the base name for the training job.\n- hyperparameters: A dictionary of hyperparameters to be passed to the custom Scikit-learn script. In this case, it sets the \"n_estimators\" hyperparameter to 100 and the \"random_state\" hyperparameter to 0.\n- use_spot_instances: This option enables the use of Amazon EC2 Spot Instances for training. Spot Instances can significantly reduce training costs.\n- max_wait: The maximum time, in seconds, that the training job is allowed to run. If the training job exceeds this time, it will be terminated.\n- max_run: The maximum time, in seconds, that a training job is allowed to run on a spot instance.\n\nOnce the sklearn_estimator is defined, you can use it to launch the SageMaker training job by calling the fit() method on it, passing the S3 paths of the training and testing datasets as arguments.","metadata":{}},{"cell_type":"code","source":"# launch training job, with asynchronous call\nsklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True)\n# sklearn_estimator.fit({\"train\": datapath}, wait=True)","metadata":{"scrolled":true,"tags":[]},"execution_count":28,"outputs":[{"name":"stdout","output_type":"stream","text":"Using provided s3_resource\n"},{"name":"stderr","output_type":"stream","text":"INFO:sagemaker:Creating training-job with name: RF-custom-sklearn-2023-06-23-17-51-03-767\n"},{"name":"stdout","output_type":"stream","text":"2023-06-23 17:51:11 Starting - Starting the training job...\n\n2023-06-23 17:51:26 Starting - Preparing the instances for training......\n\n2023-06-23 17:52:25 Downloading - Downloading input data...\n\n2023-06-23 17:53:31 Training - Training image download completed. Training in progress..2023-06-23 17:53:34,866 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n\n2023-06-23 17:53:34,870 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n\n2023-06-23 17:53:34,920 sagemaker_sklearn_container.training INFO     Invoking user training script.\n\n2023-06-23 17:53:35,093 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n\n2023-06-23 17:53:35,107 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n\n2023-06-23 17:53:35,120 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n\n2023-06-23 17:53:35,129 sagemaker-training-toolkit INFO     Invoking user script\n\nTraining Env:\n\n{\n\n    \"additional_framework_parameters\": {},\n\n    \"channel_input_dirs\": {\n\n        \"test\": \"/opt/ml/input/data/test\",\n\n        \"train\": \"/opt/ml/input/data/train\"\n\n    },\n\n    \"current_host\": \"algo-1\",\n\n    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n\n    \"hosts\": [\n\n        \"algo-1\"\n\n    ],\n\n    \"hyperparameters\": {\n\n        \"n_estimators\": 100,\n\n        \"random_state\": 0\n\n    },\n\n    \"input_config_dir\": \"/opt/ml/input/config\",\n\n    \"input_data_config\": {\n\n        \"test\": {\n\n            \"TrainingInputMode\": \"File\",\n\n            \"S3DistributionType\": \"FullyReplicated\",\n\n            \"RecordWrapperType\": \"None\"\n\n        },\n\n        \"train\": {\n\n            \"TrainingInputMode\": \"File\",\n\n            \"S3DistributionType\": \"FullyReplicated\",\n\n            \"RecordWrapperType\": \"None\"\n\n        }\n\n    },\n\n    \"input_dir\": \"/opt/ml/input\",\n\n    \"is_master\": true,\n\n    \"job_name\": \"RF-custom-sklearn-2023-06-23-17-51-03-767\",\n\n    \"log_level\": 20,\n\n    \"master_hostname\": \"algo-1\",\n\n    \"model_dir\": \"/opt/ml/model\",\n\n    \"module_dir\": \"s3://sagemaker-us-east-1-566373416292/RF-custom-sklearn-2023-06-23-17-51-03-767/source/sourcedir.tar.gz\",\n\n    \"module_name\": \"script\",\n\n    \"network_interface_name\": \"eth0\",\n\n    \"num_cpus\": 2,\n\n    \"num_gpus\": 0,\n\n    \"output_data_dir\": \"/opt/ml/output/data\",\n\n    \"output_dir\": \"/opt/ml/output\",\n\n    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n\n    \"resource_config\": {\n\n        \"current_host\": \"algo-1\",\n\n        \"current_instance_type\": \"ml.m5.large\",\n\n        \"current_group_name\": \"homogeneousCluster\",\n\n        \"hosts\": [\n\n            \"algo-1\"\n\n        ],\n\n        \"instance_groups\": [\n\n            {\n\n                \"instance_group_name\": \"homogeneousCluster\",\n\n                \"instance_type\": \"ml.m5.large\",\n\n                \"hosts\": [\n\n                    \"algo-1\"\n\n                ]\n\n            }\n\n        ],\n\n        \"network_interface_name\": \"eth0\"\n\n    },\n\n    \"user_entry_point\": \"script.py\"\n\n}\n\nEnvironment variables:\n\nSM_HOSTS=[\"algo-1\"]\n\nSM_NETWORK_INTERFACE_NAME=eth0\n\nSM_HPS={\"n_estimators\":100,\"random_state\":0}\n\nSM_USER_ENTRY_POINT=script.py\n\nSM_FRAMEWORK_PARAMS={}\n\nSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\n\nSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n\nSM_OUTPUT_DATA_DIR=/opt/ml/output/data\n\nSM_CHANNELS=[\"test\",\"train\"]\n\nSM_CURRENT_HOST=algo-1\n\nSM_MODULE_NAME=script\n\nSM_LOG_LEVEL=20\n\nSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n\nSM_INPUT_DIR=/opt/ml/input\n\nSM_INPUT_CONFIG_DIR=/opt/ml/input/config\n\nSM_OUTPUT_DIR=/opt/ml/output\n\nSM_NUM_CPUS=2\n\nSM_NUM_GPUS=0\n\nSM_MODEL_DIR=/opt/ml/model\n\nSM_MODULE_DIR=s3://sagemaker-us-east-1-566373416292/RF-custom-sklearn-2023-06-23-17-51-03-767/source/sourcedir.tar.gz\n\nSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"n_estimators\":100,\"random_state\":0},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"RF-custom-sklearn-2023-06-23-17-51-03-767\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-566373416292/RF-custom-sklearn-2023-06-23-17-51-03-767/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\n\nSM_USER_ARGS=[\"--n_estimators\",\"100\",\"--random_state\",\"0\"]\n\nSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n\nSM_CHANNEL_TEST=/opt/ml/input/data/test\n\nSM_CHANNEL_TRAIN=/opt/ml/input/data/train\n\nSM_HP_N_ESTIMATORS=100\n\nSM_HP_RANDOM_STATE=0\n\nPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n\nInvoking script with the following command:\n\n/miniconda3/bin/python script.py --n_estimators 100 --random_state 0\n\n[INFO] Extracting arguments\n\nSKLearn Version:  0.23.2\n\nJoblib Version:  1.2.0\n\n[INFO] Reading data\n\nBuilding training and testing datasets\n\nColumn order: \n\n['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g', 'touch_screen', 'wifi']\n\nLabel column is:  price_range\n\nData Shape: \n\n---- SHAPE OF TRAINING DATA (85%) ----\n\n(1700, 20)\n\n(1700,)\n\n---- SHAPE OF TESTING DATA (15%) ----\n\n(300, 20)\n\n(300,)\n\nTraining RandomForest Model.....\n\n[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n\nbuilding tree 1 of 100building tree 2 of 100\n\nbuilding tree 3 of 100\n\nbuilding tree 4 of 100\n\nbuilding tree 5 of 100building tree 6 of 100\n\nbuilding tree 7 of 100\n\nbuilding tree 8 of 100\n\nbuilding tree 9 of 100\n\nbuilding tree 10 of 100\n\nbuilding tree 11 of 100\n\nbuilding tree 12 of 100\n\nbuilding tree 13 of 100building tree 14 of 100\n\nbuilding tree 15 of 100\n\nbuilding tree 16 of 100\n\nbuilding tree 17 of 100building tree 18 of 100\n\nbuilding tree 19 of 100\n\nbuilding tree 20 of 100\n\nbuilding tree 21 of 100\n\nbuilding tree 22 of 100\n\nbuilding tree 23 of 100\n\nbuilding tree 24 of 100\n\nbuilding tree 25 of 100\n\nbuilding tree 26 of 100\n\nbuilding tree 27 of 100\n\nbuilding tree 28 of 100\n\nbuilding tree 29 of 100\n\n[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.1s\n\nbuilding tree 30 of 100\n\nbuilding tree 31 of 100\n\nbuilding tree 32 of 100\n\nbuilding tree 33 of 100\n\nbuilding tree 34 of 100\n\nbuilding tree 35 of 100building tree 36 of 100\n\nbuilding tree 37 of 100\n\nbuilding tree 38 of 100\n\nbuilding tree 39 of 100\n\nbuilding tree 40 of 100\n\nbuilding tree 41 of 100building tree 42 of 100\n\nbuilding tree 43 of 100\n\nbuilding tree 44 of 100\n\nbuilding tree 45 of 100\n\nbuilding tree 46 of 100\n\nbuilding tree 47 of 100\n\nbuilding tree 48 of 100\n\nbuilding tree 49 of 100\n\nbuilding tree 50 of 100\n\nbuilding tree 51 of 100\n\nbuilding tree 52 of 100\n\nbuilding tree 53 of 100building tree 54 of 100\n\nbuilding tree 55 of 100\n\nbuilding tree 56 of 100\n\nbuilding tree 57 of 100\n\nbuilding tree 58 of 100\n\nbuilding tree 59 of 100\n\nbuilding tree 60 of 100\n\nbuilding tree 61 of 100building tree 62 of 100\n\nbuilding tree 63 of 100\n\nbuilding tree 64 of 100\n\nbuilding tree 65 of 100\n\nbuilding tree 66 of 100\n\nbuilding tree 67 of 100\n\nbuilding tree 68 of 100\n\nbuilding tree 69 of 100\n\nbuilding tree 70 of 100\n\nbuilding tree 71 of 100\n\nbuilding tree 72 of 100\n\nbuilding tree 73 of 100\n\nbuilding tree 74 of 100\n\nbuilding tree 75 of 100\n\nbuilding tree 76 of 100\n\nbuilding tree 77 of 100\n\nbuilding tree 78 of 100\n\nbuilding tree 79 of 100\n\nbuilding tree 80 of 100\n\nbuilding tree 81 of 100\n\nbuilding tree 82 of 100\n\nbuilding tree 83 of 100\n\nbuilding tree 84 of 100\n\nbuilding tree 85 of 100\n\nbuilding tree 86 of 100\n\nbuilding tree 87 of 100\n\nbuilding tree 88 of 100\n\nbuilding tree 89 of 100\n\nbuilding tree 90 of 100\n\nbuilding tree 91 of 100\n\nbuilding tree 92 of 100\n\nbuilding tree 93 of 100\n\nbuilding tree 94 of 100\n\nbuilding tree 95 of 100\n\nbuilding tree 96 of 100\n\nbuilding tree 97 of 100\n\nbuilding tree 98 of 100\n\nbuilding tree 99 of 100\n\nbuilding tree 100 of 100\n\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n\nModel persisted at /opt/ml/model/model.joblib\n\n[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n\n[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.0s\n\n[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n\n---- METRICS RESULTS FOR TESTING DATA ----\n\nTotal Rows are:  300\n\n[TESTING] Model Accuracy is:  0.8833333333333333\n\n[TESTING] Testing Report: \n\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97        69\n\n           1       0.85      0.80      0.83        66\n\n           2       0.80      0.77      0.79        74\n\n           3       0.91      0.95      0.93        91\n\n    accuracy                           0.88       300\n\n   macro avg       0.88      0.88      0.88       300\n\nweighted avg       0.88      0.88      0.88       300\n\n2023-06-23 17:53:36,788 sagemaker-containers INFO     Reporting training SUCCESS\n\n\n\n2023-06-23 17:53:42 Uploading - Uploading generated training model\n\n2023-06-23 17:54:51 Completed - Training job completed\n\nTraining seconds: 146\n\nBillable seconds: 108\n\nManaged Spot Training savings: 26.0%\n"}]},{"cell_type":"markdown","source":"The code provided launches a SageMaker training job using the previously defined sklearn_estimator with an asynchronous call. The fit() method is used to start the training job, and the training data is passed to the estimator in the form of a dictionary containing S3 paths to the training and testing datasets.\n\nHere's what the code does:\n\n1. sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True): This line starts the SageMaker training job using the sklearn_estimator. The fit() method takes the input data as a dictionary where the keys are strings that represent the names of the input channels specified in the custom Scikit-learn script, and the values are the S3 paths to the corresponding datasets.\n- \"train\": trainpath: The S3 path to the training dataset previously uploaded to S3 is provided as the value for the \"train\" key.\n- \"test\": testpath: The S3 path to the testing dataset previously uploaded to S3 is provided as the value for the \"test\" key.\n- wait=True: The wait parameter is set to True, which means that the fit() method will wait for the training job to complete before proceeding to the next line of code. This makes the call synchronous, and the script will continue only after the training job is finished.\n\n2.  sklearn_estimator.fit({\"train\": datapath}, wait=True): This is a commented line of code that seems to be a duplicate or an example of how the fit() method can be called with only the training dataset. It is not executed since it is commented out (denoted by the '#' symbol).\n\nBy calling sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True), the training job will be launched using the provided data, and the script will wait for the job to finish before proceeding further. Once the training job is complete, the trained model will be saved in the specified S3 location as defined by the sklearn_estimator configuration.","metadata":{}},{"cell_type":"code","source":"sklearn_estimator.latest_training_job.wait(logs=\"None\")\nartifact = sm_boto3.describe_training_job(\n    TrainingJobName=sklearn_estimator.latest_training_job.name\n)[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n\nprint(\"Model artifact persisted at \" + artifact)","metadata":{"tags":[]},"execution_count":29,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\n2023-06-23 17:54:51 Starting - Preparing the instances for training\n\n2023-06-23 17:54:51 Downloading - Downloading input data\n\n2023-06-23 17:54:51 Training - Training image download completed. Training in progress.\n\n2023-06-23 17:54:51 Uploading - Uploading generated training model\n\n2023-06-23 17:54:51 Completed - Training job completed\n\nModel artifact persisted at s3://sagemaker-us-east-1-566373416292/RF-custom-sklearn-2023-06-23-17-51-03-767/output/model.tar.gz\n"}]},{"cell_type":"markdown","source":"In the provided code, after launching the SageMaker training job with the sklearn_estimator.fit() method, the script waits for the training job to complete using the wait() method of the latest training job created by sklearn_estimator.\n\nHere's what the code does:\n\n1. sklearn_estimator.latest_training_job.wait(logs=\"None\"): This line waits for the training job represented by sklearn_estimator.latest_training_job to complete. The wait() method is called with logs=\"None\" to suppress the display of logs while waiting for the job to finish. This makes the script synchronous, and it will wait until the training job completes before proceeding.\n2. artifact = sm_boto3.describe_training_job(TrainingJobName=sklearn_estimator.latest_training_job.name)[\"ModelArtifacts\"][\"S3ModelArtifacts\"]: After the training job is completed, the code uses the SageMaker Boto3 client (sm_boto3) to describe the training job and retrieve the S3 path to the trained model artifacts. The describe_training_job method is called with the TrainingJobName set to sklearn_estimator.latest_training_job.name, which retrieves details of the latest training job. The ModelArtifacts field contains information about the model artifacts, and the S3ModelArtifacts field contains the S3 path to the trained model.\n3. print(\"Model artifact persisted at \" + artifact): The S3 path to the trained model is printed, indicating where the model artifacts are stored after the training job is completed.\n\nBy using wait() and describe_training_job, the script ensures that it waits for the training job to finish before proceeding to retrieve and print the S3 path to the trained model. This way, you can be sure that the trained model is ready and accessible before further processing or deploying it.","metadata":{}},{"cell_type":"code","source":"artifact","metadata":{},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":["'s3://sagemaker-us-east-1-566373416292/RF-custom-sklearn-2023-06-23-17-51-03-767/output/model.tar.gz'"]},"metadata":{}}]},{"cell_type":"markdown","source":"The variable artifact contains the S3 path to the trained model artifacts that were generated during the SageMaker training job. These artifacts include the model itself and any associated files created during the training process.\n\nThe specific content of the artifact variable will be a string representing the S3 path.","metadata":{}},{"cell_type":"code","source":"from sagemaker.sklearn.model import SKLearnModel\nfrom time import gmtime, strftime\n\nmodel_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nmodel = SKLearnModel(\n    name =  model_name,\n    model_data=artifact,\n    role=\"arn:aws:iam::566373416292:role/service-role/AmazonSageMaker-ExecutionRole-20230120T164209\",\n    entry_point=\"script.py\",\n    framework_version=FRAMEWORK_VERSION,\n)","metadata":{"tags":[]},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"In the code, a SageMaker SKLearnModel is created based on the trained model artifacts from the previous training job. The SKLearnModel serves as a SageMaker endpoint for deploying the trained Scikit-learn model.\n\nHere's what the code does:\n\n1. model_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()): This line generates a unique name for the SageMaker model. The name is a combination of the base name \"Custom-sklearn-model-\" and a timestamp in the format \"YYYY-MM-DD-HH-MM-SS\". This ensures that each model created will have a distinct name.\n2. model = SKLearnModel(...): This line creates the SKLearnModel instance, representing the SageMaker model to be deployed. The instance is initialized with the following parameters:\n- name: The name of the SageMaker model. It is set to the value generated in the previous step (model_name).\n- model_data: The S3 path to the trained model artifacts. This is the value of the artifact variable, which points to the location of the serialized model in S3.\n- role: The Amazon Resource Name (ARN) of the IAM role that SageMaker will assume to perform tasks on your behalf during model deployment.\n- entry_point: The name of the script file that contains the custom Scikit-learn model implementation. In this case, it is \"script.py\".\n- framework_version: The version of Scikit-learn to be used during model deployment. The provided version is \"0.23-1\".\n\nOnce the model instance is created, you can deploy it as a SageMaker endpoint to make predictions on new data.","metadata":{}},{"cell_type":"code","source":"model_name","metadata":{},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":["'Custom-sklearn-model-2023-06-23-18-01-16'"]},"metadata":{}}]},{"cell_type":"markdown","source":"The variable model_name contains the name of the SageMaker model that will be created for deploying the trained Scikit-learn model. ","metadata":{}},{"cell_type":"code","source":"##Endpoints deployment\nendpoint_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nprint(\"EndpointName={}\".format(endpoint_name))\n\npredictor = model.deploy(\n    initial_instance_count=1,\n    instance_type=\"ml.m4.xlarge\",\n    endpoint_name=endpoint_name,\n)","metadata":{"tags":[]},"execution_count":34,"outputs":[{"name":"stdout","output_type":"stream","text":"EndpointName=Custom-sklearn-model-2023-06-23-18-02-06\n"},{"name":"stderr","output_type":"stream","text":"INFO:sagemaker:Creating model with name: Custom-sklearn-model-2023-06-23-18-01-16\n\nINFO:sagemaker:Creating endpoint-config with name Custom-sklearn-model-2023-06-23-18-02-06\n\nINFO:sagemaker:Creating endpoint with name Custom-sklearn-model-2023-06-23-18-02-06\n"}]},{"cell_type":"markdown","source":"The code provided deploys the trained Scikit-learn model as a SageMaker endpoint using the model.deploy() method. This allows you to create a live endpoint to make predictions on new data.\n\nHere's what the code does:\n\n- endpoint_name = \"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()): This line generates a unique name for the SageMaker endpoint. It follows the same format as in the previous example, where endpoint_name is a combination of the base name \"Custom-sklearn-model-\" and a timestamp in the format \"YYYY-MM-DD-HH-MM-SS\". This ensures that each endpoint created will have a distinct name.\n- print(\"EndpointName={}\".format(endpoint_name)): This line prints the name of the endpoint that will be created. The printed value will be in the format of \"EndpointName=Custom-sklearn-model-YYYY-MM-DD-HH-MM-SS\".\n- predictor = model.deploy(..., endpoint_name=endpoint_name): This line deploys the SageMaker endpoint using the trained Scikit-learn model. The deploy() method takes the following parameters:\n- initial_instance_count: The number of instances to be launched for the endpoint. In this case, a single instance (initial_instance_count=1) will be launched.\n- instance_type: The type of EC2 instance to be used for the endpoint. In this example, \"ml.m4.xlarge\" instances will be used.\n- endpoint_name: The name for the endpoint. It is set to the value generated in the first step (endpoint_name). The endpoint will be accessible using this name.\n\nAfter executing this code, the Scikit-learn model will be deployed as a SageMaker endpoint with the specified instance configuration, and you can use the predictor object to make real-time predictions by sending new data to the endpoint. For example:","metadata":{}},{"cell_type":"code","source":"endpoint_name","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The variable endpoint_name contains the name of the SageMaker endpoint that was created for deploying the trained Scikit-learn model. This endpoint serves as an API endpoint that you can use to make real-time predictions on new data.","metadata":{}},{"cell_type":"code","source":"testX[features][0:2].values.tolist()","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code provided extracts a subset of data from the 'testX' DataFrame, specifically the first two rows, and converts it into a list. The selected subset includes only the columns specified in the 'features' list.\n\nHere's what the code does:\n\n- testX[features]: This part of the code selects the columns specified in the 'features' list from the 'testX' DataFrame. It effectively filters the 'testX' DataFrame to retain only the specified columns.\n- [0:2]: This slice notation selects the first two rows of the filtered DataFrame, i.e., the first and second row.\n- values.tolist(): The 'values' attribute of the DataFrame is used to get the values of the selected subset as a NumPy array. The 'tolist()' method then converts this NumPy array into a Python list.\n\nThe resulting output will be a Python list containing the selected data from the 'testX' DataFrame, limited to the first two rows and only the columns specified in the 'features' list.","metadata":{}},{"cell_type":"code","source":"print(predictor.predict(testX[features][0:2].values.tolist()))","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The provided code uses the SageMaker predictor object to make predictions on the subset of data extracted from the 'testX' DataFrame, containing the first two rows and only the columns specified in the 'features' list.\n\nHere's what the code does:\n\n- testX[features][0:2].values.tolist(): This part of the code selects the subset of data from the 'testX' DataFrame, containing the first two rows and only the columns specified in the 'features' list. The data is extracted as a list of lists, where each sublist represents a row of data, and each element in the sublist represents the value of a specific feature for that row. The resulting format is similar to the one shown in the previous example.\n- predictor.predict(...): The predict() method of the predictor object is called with the selected subset of data as input. This method sends the data to the deployed SageMaker endpoint and receives the model's predictions in return.\n- print(...): The predictions obtained from the predict() method are printed to the console.","metadata":{}},{"cell_type":"code","source":"sm_boto3.delete_endpoint(EndpointName=endpoint_name)","metadata":{"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code provided deletes the SageMaker endpoint with the name specified in the endpoint_name variable. It uses the delete_endpoint function from the sm_boto3 SageMaker client to initiate the deletion of the endpoint.\n\nHere's what the code does:\n\nsm_boto3.delete_endpoint(EndpointName=endpoint_name): This line calls the delete_endpoint function of the SageMaker client (sm_boto3) and passes the name of the endpoint to be deleted as the EndpointName parameter. The EndpointName should match the name of the endpoint that was created earlier using the same name.\nAfter executing this code, the specified SageMaker endpoint will be deleted, and the associated compute resources used for hosting the endpoint will be terminated. It's a good practice to delete unused endpoints to avoid unnecessary charges and resource consumption.\n\nKeep in mind that once the endpoint is deleted, you won't be able to use it for making predictions until you redeploy the model and create a new endpoint. If you plan to use the model again, you'll need to re-deploy it using the previous steps, starting from creating an SKLearnModel and deploying it as an endpoint.","metadata":{}}]}